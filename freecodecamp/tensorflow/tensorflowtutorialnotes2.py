# -*- coding: utf-8 -*-
"""TensorflowTutorialNotes2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14BhBtcEI_X6XHTgRB1YG91RSYiV4ZqlB

#Part 2 of the tensorflow tutorial notes
# Setup 

lets again start with the imports, device, and distribution strategy on TPU. If you did not understand any of the above lines then look at part 1 again.

Also I forgot to write it out previously but take a look at https://www.tensorflow.org/tutorials
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
import os

## Set device
resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')
tf.config.experimental_connect_to_cluster(resolver)
# This is the TPU initialization code that has to be at the beginning.
tf.tpu.experimental.initialize_tpu_system(resolver)
print("All devices: ", tf.config.list_logical_devices('TPU'))

# set device as tpu 
tf.device('/TPU:0')

# distrubtion stratgey
tfd = tf.distribute.TPUStrategy(resolver)

"""# Tensorflow Core Learning Algos

- linear regression
- classification
- clustering
- HMM -> Hidden Markov Models

these are the fundamental algos that can be expanded on.

## Linear Regression

The most basic form of machine learning and is used to predict numeric values.

https://www.tensorflow.org/tutorials/estimator/linear

as a summary linear regression which is a basic form of ml where you linear corespondance between datapoints.

below I have draw a graph
"""

import matplotlib.pyplot as plt
import numpy as np

x = [1, 2, 5, 7, 8]
y = [3, 10, 11, 15, 18]
plt.plot(x, y, 'ro')
plt.axis([0, 10, 0, 20]) # 0 to 10 x axis and 0 to 20 y axis

"""as you can see there is already a linear corespondance and you can draw a line through it to predict y points for x values with a straight line

the formula would be y = mx + b and here below is an example of the line of best fit for the above graph
"""

plt.plot(x, y, 'ro')
plt.axis([0, 10, 0, 20])

plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))
plt.show()

"""The blue line can be used in the future to predict more values

### Linear Regression Project

This is a simple project to use linear regression.
"""

!pip install -q sklearn

from __future__ import absolute_import, division, print_function, unicode_literals

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import clear_output
from six.moves import urllib

import tensorflow.compat.v2.feature_column as fc

"""Lets load the data set from a a few files for ***The Titanic*** and who is going to die or surrive."""

dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data
dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data

dftrain.head()

dfeval.head()

y_train = dftrain.pop('survived') # removed and stored survided in ytain 
y_eval = dfeval.pop('survived') # removed and stroed survived in yeval

dftrain.head()

dfeval.head()

"""lets describe all the data after viewing them"""

dftrain.describe()

dftrain.shape

"""as we can see we have 627 stuff / entries and 9 features"""

dftrain.age.hist(bins=20)

dftrain.sex.value_counts().plot(kind='barh')

pd.concat([dftrain, y_train], axis=1).groupby('sex').survived.mean().plot(kind='barh').set_xlabel('% survive')

CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',
                       'embark_town', 'alone']
NUMERIC_COLUMNS = ['age', 'fare']

feature_columns = []
for feature_name in CATEGORICAL_COLUMNS:
  vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column
  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))

for feature_name in NUMERIC_COLUMNS:
  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))

print(feature_columns)

"""#### Training process

epochs baasically spliting up the data and batches to allow the model to train on. 
"""

def make_input_fn(data_df, label_df, num_epochs=200, shuffle=True, batch_size=128):
  def input_function():  # inner function, this will be returned
    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label
    if shuffle:
      ds = ds.shuffle(1000)  # randomize order of data
    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs
    return ds  # return a batch of the dataset
  return input_function  # return a function object for use

train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model
eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)

linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)

with tfd.scope():
  linear_est.train(train_input_fn)
  result = linear_est.evaluate(eval_input_fn)

print(result['accuracy'])  # the result variable is simply a dict of stats about our model

print(result)

# not great at predicting one output but larger batches of data
# lets make preddiction for every single point of dataset
with tfd.scope():
  result = list(linear_est.predict(eval_input_fn))
print(result)

print(result[0]) #prediction for one

def person_stat_death(n):
  print("----------")
  print("Estimated: ")
  print("------")
  print(dfeval.loc[n])
  print(result[n]['probabilities'][1])
  print("-------")
  print("Actual: ")
  print("-------")
  print(y_eval.loc[n])
  print("----------")

person_stat_death(2)
person_stat_death(3)
person_stat_death(4)

"""## Classification """